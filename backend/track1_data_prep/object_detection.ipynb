{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a1542c",
   "metadata": {},
   "source": [
    "#Preprocessing MP4 videos into Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9187fd4",
   "metadata": {},
   "source": [
    "\"\"\"MP4 croping\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79875b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Dhanvanth\\SL\\test\\W23P55.mp4 -> D:\\Dhanvanth\\SL\\videos_cropped1\\test\\W23P55.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# -------------------\n",
    "# Step 1: Get bounding box for one frame\n",
    "# -------------------\n",
    "def get_person_bbox(frame, pose_model):\n",
    "    results = pose_model.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if not results.pose_landmarks:\n",
    "        return None\n",
    "    \n",
    "    h, w, _ = frame.shape\n",
    "    xs = [lm.x * w for lm in results.pose_landmarks.landmark]\n",
    "    ys = [lm.y * h for lm in results.pose_landmarks.landmark]\n",
    "    \n",
    "    x_min, x_max = int(min(xs)), int(max(xs))\n",
    "    y_min, y_max = int(min(ys)), int(max(ys))\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "# -------------------\n",
    "# Step 2: Find bounding box for whole video\n",
    "# -------------------\n",
    "def get_video_bbox(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    with mp_pose.Pose(static_image_mode=False) as pose:\n",
    "        x_min_total, y_min_total = 1e9, 1e9\n",
    "        x_max_total, y_max_total = 0, 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            bbox = get_person_bbox(frame, pose)\n",
    "            if bbox:\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                x_min_total = min(x_min_total, x_min)\n",
    "                y_min_total = min(y_min_total, y_min)\n",
    "                x_max_total = max(x_max_total, x_max)\n",
    "                y_max_total = max(y_max_total, y_max)\n",
    "    \n",
    "    cap.release()\n",
    "    if x_max_total == 0 and y_max_total == 0:\n",
    "        return None\n",
    "    return x_min_total, y_min_total, x_max_total, y_max_total\n",
    "\n",
    "# -------------------\n",
    "# Step 3: Crop with fixed square size\n",
    "# -------------------\n",
    "def crop_person_from_video(input_path, output_path, output_size=256):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    bbox = get_video_bbox(input_path)\n",
    "    if not bbox:\n",
    "        print(f\"No person detected in {input_path}\")\n",
    "        return\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    \n",
    "    # Add padding\n",
    "    x_min = max(0, x_min-20)\n",
    "    y_min = max(0, y_min-20)\n",
    "    x_max = int(x_max+20)\n",
    "    y_max = int(y_max+20)\n",
    "\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    x_max = min(w, x_max)\n",
    "    y_max = min(h, y_max)\n",
    "\n",
    "    # Make it square\n",
    "    box_w = x_max - x_min\n",
    "    box_h = y_max - y_min\n",
    "    side = max(box_w, box_h)\n",
    "    cx = (x_min + x_max) // 2\n",
    "    cy = (y_min + y_max) // 2\n",
    "    x_min = max(0, cx - side // 2)\n",
    "    x_max = min(w, cx + side // 2)\n",
    "    y_min = max(0, cy - side // 2)\n",
    "    y_max = min(h, cy + side // 2)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (output_size, output_size))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cropped = frame[y_min:y_max, x_min:x_max]\n",
    "        resized = cv2.resize(cropped, (output_size, output_size))\n",
    "        out.write(resized)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# -------------------\n",
    "# Step 4: Process all videos in folder\n",
    "# -------------------\n",
    "def crop_videos_in_folder(input_folder, output_folder, output_size=256):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp4\"):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            print(f\"Processing {input_path} -> {output_path}\")\n",
    "            crop_person_from_video(input_path, output_path, output_size)\n",
    "\n",
    "# -------------------\n",
    "# ðŸš€ Run for your LOCK folder\n",
    "# -------------------\n",
    "input_folder = r\"D:\\Dhanvanth\\SL\\test\"\n",
    "output_folder = r\"D:\\Dhanvanth\\SL\\videos_cropped1\\test\"\n",
    "\n",
    "# All outputs will be 256x256 square videos\n",
    "crop_videos_in_folder(input_folder, output_folder, output_size=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabe405",
   "metadata": {},
   "source": [
    "\"\"\"Croped MP4 to adding pose to it\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27df4aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Dhanvanth\\SL\\videos_cropped1\\test\\W23P55.mp4 -> D:\\Dhanvanth\\SL\\videos_pose1\\test\\W23P55.mp4\n",
      "Pose overlay saved -> D:\\Dhanvanth\\SL\\videos_pose1\\test\\W23P55.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# -------------------\n",
    "# Draw pose on a video\n",
    "# -------------------\n",
    "def draw_pose_on_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Convert to RGB\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(rgb)\n",
    "\n",
    "            # Draw pose if detected\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, \n",
    "                    results.pose_landmarks, \n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2),  # keypoints\n",
    "                    mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)   # skeleton\n",
    "                )\n",
    "            \n",
    "            out.write(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Pose overlay saved -> {output_path}\")\n",
    "\n",
    "# -------------------\n",
    "# Process all cropped videos in a folder\n",
    "# -------------------\n",
    "def add_pose_to_videos(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp4\"):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            print(f\"Processing {input_path} -> {output_path}\")\n",
    "            draw_pose_on_video(input_path, output_path)\n",
    "\n",
    "# -------------------\n",
    "# ðŸš€ Run for your LOCK cropped videos\n",
    "# -------------------\n",
    "input_cropped_folder = r\"D:\\Dhanvanth\\SL\\videos_cropped1\\test\"\n",
    "output_pose_folder   = r\"D:\\Dhanvanth\\SL\\videos_pose1\\test\"\n",
    "\n",
    "add_pose_to_videos(input_cropped_folder, output_pose_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab4be7",
   "metadata": {},
   "source": [
    "\"\"\"holistic pose\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bcbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Dhanvanth\\SL\\videos_cropped1\\test\\W23P55.mp4 -> D:\\Dhanvanth\\SL\\videos_pose1\\test\\W23P55.mp4\n",
      "Holistic pose overlay saved -> D:\\Dhanvanth\\SL\\videos_pose1\\test\\W23P55.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# âœ… Use Holistic instead of only Pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# -------------------\n",
    "# Draw holistic landmarks on a video\n",
    "# -------------------\n",
    "def draw_holistic_on_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as holistic:\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert to RGB\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(rgb)\n",
    "\n",
    "            # -------------------\n",
    "            # Draw Pose (33 landmarks)\n",
    "            # -------------------\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,0), thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=(0,0,255), thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "            # -------------------\n",
    "            # Draw Left & Right Hands (21 + 21 landmarks)\n",
    "            # -------------------\n",
    "            if results.left_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(255,0,0), thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,255), thickness=1, circle_radius=1)\n",
    "                )\n",
    "            if results.right_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(255,0,0), thickness=1, circle_radius=1),\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,255), thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "            # -------------------\n",
    "            # (Optional) Draw Face (468 landmarks â€“ can be disabled)\n",
    "            # -------------------\n",
    "            # if results.face_landmarks:\n",
    "            #     mp_drawing.draw_landmarks(\n",
    "            #         frame, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "            #         mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "            #         mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "            #     )\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Holistic pose overlay saved -> {output_path}\")\n",
    "\n",
    "# -------------------\n",
    "# Process all cropped videos in a folder\n",
    "# -------------------\n",
    "def add_holistic_to_videos(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp4\"):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            print(f\"Processing {input_path} -> {output_path}\")\n",
    "            draw_holistic_on_video(input_path, output_path)\n",
    "\n",
    "# -------------------\n",
    "# ðŸš€ Run for your test cropped videos\n",
    "# -------------------\n",
    "input_cropped_folder = r\"D:\\Dhanvanth\\SL\\videos_cropped1\\test\"\n",
    "output_pose_folder   = r\"D:\\Dhanvanth\\SL\\videos_pose1\\test\"\n",
    "\n",
    "add_holistic_to_videos(input_cropped_folder, output_pose_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25bf41",
   "metadata": {},
   "source": [
    "\"\"\"pose to npz\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386cf3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Dhanvanth\\SL\\videos_pose1\\test\\W23P55.mp4 -> D:\\Dhanvanth\\SL\\pose_to_npy\\test\\W23P55.npz\n",
      "Saved: D:\\Dhanvanth\\SL\\pose_to_npy\\test\\W23P55.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# -------------------\n",
    "# Function to extract pose/hand keypoints from one video\n",
    "# -------------------\n",
    "def extract_pose_to_npz(video_path, out_npz_path, include_face=False, output_size=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    pixel_coords = []  # list of (K,2)\n",
    "    masks = []\n",
    "\n",
    "    with mp_holistic.Holistic(static_image_mode=False,\n",
    "                              min_detection_confidence=0.5,\n",
    "                              min_tracking_confidence=0.5) as holistic:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            h, w = frame.shape[:2]\n",
    "            if output_size is not None:\n",
    "                frame = cv2.resize(frame, (output_size, output_size))\n",
    "                h, w = output_size, output_size\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(rgb)\n",
    "\n",
    "            # initialize all K to nan and mask False\n",
    "            K = 33 + 21 + 21\n",
    "            coords = np.full((K, 2), np.nan, dtype=np.float32)\n",
    "            mask = np.zeros((K,), dtype=np.uint8)\n",
    "\n",
    "            # pose (33)\n",
    "            if results.pose_landmarks:\n",
    "                for i, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                    coords[i, 0] = lm.x * w\n",
    "                    coords[i, 1] = lm.y * h\n",
    "                    mask[i] = 1\n",
    "\n",
    "            # left hand (21) -> indices 33..53\n",
    "            if results.left_hand_landmarks:\n",
    "                for i, lm in enumerate(results.left_hand_landmarks.landmark):\n",
    "                    coords[33 + i, 0] = lm.x * w\n",
    "                    coords[33 + i, 1] = lm.y * h\n",
    "                    mask[33 + i] = 1\n",
    "\n",
    "            # right hand (21) -> indices 54..74\n",
    "            if results.right_hand_landmarks:\n",
    "                for i, lm in enumerate(results.right_hand_landmarks.landmark):\n",
    "                    coords[54 + i, 0] = lm.x * w\n",
    "                    coords[54 + i, 1] = lm.y * h\n",
    "                    mask[54 + i] = 1\n",
    "\n",
    "            pixel_coords.append(coords)\n",
    "            masks.append(mask)\n",
    "\n",
    "    cap.release()\n",
    "    pixel_coords = np.stack(pixel_coords, axis=0)   # (T, K, 2)\n",
    "    masks = np.stack(masks, axis=0).astype(np.uint8) # (T, K)\n",
    "\n",
    "    # Normalization\n",
    "    T, K, _ = pixel_coords.shape\n",
    "    norm = np.zeros_like(pixel_coords, dtype=np.float32)\n",
    "    for t in range(T):\n",
    "        pts = pixel_coords[t]  # (K,2)\n",
    "        mask = masks[t].astype(bool)\n",
    "\n",
    "        # origin = mid-hip (23,24) if available\n",
    "        origin = None\n",
    "        if mask[23] and mask[24]:\n",
    "            origin = (pts[23] + pts[24]) / 2.0\n",
    "        else:\n",
    "            visible_pose_idx = np.where(mask[:33])[0]\n",
    "            if len(visible_pose_idx) > 0:\n",
    "                origin = np.nanmean(pts[visible_pose_idx], axis=0)\n",
    "        if origin is None:\n",
    "            origin = np.array([0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "        # scale = shoulder distance (11,12) else bbox diag\n",
    "        if mask[11] and mask[12]:\n",
    "            scale = np.linalg.norm(pts[11] - pts[12])\n",
    "            if scale < 1e-3:\n",
    "                scale = 1.0\n",
    "        else:\n",
    "            vis_pts = pts[mask.astype(bool)]\n",
    "            if vis_pts.size == 0:\n",
    "                scale = 1.0\n",
    "            else:\n",
    "                bbox = np.nanmin(vis_pts, axis=0), np.nanmax(vis_pts, axis=0)\n",
    "                diag = np.linalg.norm(bbox[1] - bbox[0])\n",
    "                scale = max(diag, 1.0)\n",
    "\n",
    "        norm[t] = (np.nan_to_num(pts) - origin[None, :]) / float(scale)\n",
    "\n",
    "    # save\n",
    "    np.savez_compressed(out_npz_path,\n",
    "                        xy_pixels=pixel_coords.astype(np.float32),\n",
    "                        xy_norm=norm.astype(np.float32),\n",
    "                        mask=masks,\n",
    "                        fps=float(fps))\n",
    "    print(\"Saved:\", out_npz_path)\n",
    "    return out_npz_path\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Batch processing: convert all videos in folder\n",
    "# -------------------\n",
    "def convert_videos_to_npz(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(input_folder, file_name)\n",
    "            npz_name = os.path.splitext(file_name)[0] + \".npz\"\n",
    "            out_path = os.path.join(output_folder, npz_name)\n",
    "            print(f\"Processing {video_path} -> {out_path}\")\n",
    "            extract_pose_to_npz(video_path, out_path)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# ðŸš€ Run for your dataset\n",
    "# -------------------\n",
    "input_pose_folder = r\"D:\\Dhanvanth\\SL\\videos_pose1\\test\"\n",
    "output_npy_folder = r\"D:\\Dhanvanth\\SL\\pose_to_npy\\test\"\n",
    "\n",
    "convert_videos_to_npz(input_pose_folder, output_npy_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2164338",
   "metadata": {},
   "source": [
    "\"\"\"holistic pose\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44945c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Dhanvanth\\SL\\videos_cropped1\\test\\W23P55.mp4 -> D:\\Dhanvanth\\SL\\videos_pose_holistic\\test\\W23P55.mp4\n",
      "Pose overlay saved -> D:\\Dhanvanth\\SL\\videos_pose_holistic\\test\\W23P55.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# -------------------\n",
    "# Draw holistic pose/hand landmarks on one video\n",
    "# -------------------\n",
    "def draw_pose_on_video_holistic(input_path, output_path, skeleton_only=False, output_size=None):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    if output_size:\n",
    "        out_w, out_h = output_size, output_size\n",
    "    else:\n",
    "        out_w, out_h = w, h\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, float(fps), (out_w, out_h))\n",
    "\n",
    "    with mp_holistic.Holistic(static_image_mode=False,\n",
    "                              min_detection_confidence=0.5,\n",
    "                              min_tracking_confidence=0.5) as holistic:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if output_size:\n",
    "                frame_proc = cv2.resize(frame, (output_size, output_size))\n",
    "            else:\n",
    "                frame_proc = frame.copy()\n",
    "\n",
    "            rgb = cv2.cvtColor(frame_proc, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(rgb)\n",
    "\n",
    "            # Skeleton-only â†’ black canvas, else original frame\n",
    "            canvas = np.zeros_like(frame_proc) if skeleton_only else frame_proc\n",
    "\n",
    "            # Pose (33 landmarks)\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    canvas,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_holistic.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(0,0,255), thickness=2)\n",
    "                )\n",
    "\n",
    "            # Left hand (21 landmarks)\n",
    "            if results.left_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    canvas,\n",
    "                    results.left_hand_landmarks,\n",
    "                    mp_holistic.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(255,0,0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,255), thickness=2)\n",
    "                )\n",
    "\n",
    "            # Right hand (21 landmarks)\n",
    "            if results.right_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    canvas,\n",
    "                    results.right_hand_landmarks,\n",
    "                    mp_holistic.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(255,0,0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(0,255,255), thickness=2)\n",
    "                )\n",
    "\n",
    "            out.write(canvas)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Pose overlay saved ->\", output_path)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Batch process: all videos in a folder\n",
    "# -------------------\n",
    "def add_holistic_pose_to_videos(input_folder, output_folder,\n",
    "                                skeleton_only=False, output_size=None):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp4\"):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            print(f\"Processing {input_path} -> {output_path}\")\n",
    "            draw_pose_on_video_holistic(input_path, output_path,\n",
    "                                        skeleton_only=skeleton_only,\n",
    "                                        output_size=output_size)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# ðŸš€ Run for your dataset\n",
    "# -------------------\n",
    "input_videos = r\"D:\\Dhanvanth\\SL\\videos_cropped1\\test\"\n",
    "output_videos = r\"D:\\Dhanvanth\\SL\\videos_pose_holistic\\test\"\n",
    "\n",
    "# Example 1: Overlay on original video\n",
    "# add_holistic_pose_to_videos(input_videos, output_videos,\n",
    "#                             skeleton_only=False, output_size=256)\n",
    "\n",
    "# Example 2: Skeleton-only version\n",
    "add_holistic_pose_to_videos(input_videos, output_videos,\n",
    "                            skeleton_only=True, output_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb87081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def resample_sequence(xy, mask, target_len):\n",
    "    # xy: (T, K, 2), mask: (T, K)\n",
    "    T, K, _ = xy.shape\n",
    "    if T == target_len:\n",
    "        return xy, mask\n",
    "    # handle NaNs: replace NaN with linear interpolation per joint\n",
    "    xy_filled = xy.copy()\n",
    "    for k in range(K):\n",
    "        for dim in range(2):\n",
    "            series = xy_filled[:, k, dim]\n",
    "            valid = ~np.isnan(series)\n",
    "            if valid.sum() == 0:\n",
    "                xy_filled[:, k, dim] = 0.0\n",
    "            elif valid.sum() == 1:\n",
    "                xy_filled[:, k, dim] = series[valid][0]\n",
    "            else:\n",
    "                xp = np.where(valid)[0]\n",
    "                fp = series[valid]\n",
    "                x = np.arange(T)\n",
    "                xy_filled[:, k, dim] = np.interp(x, xp, fp)\n",
    "    # now interpolate in time to target_len\n",
    "    old_idx = np.linspace(0, T-1, T)\n",
    "    new_idx = np.linspace(0, T-1, target_len)\n",
    "    out = np.zeros((target_len, K, 2), dtype=xy.dtype)\n",
    "    out_mask = np.zeros((target_len, K), dtype=mask.dtype)\n",
    "    for k in range(K):\n",
    "        for d in range(2):\n",
    "            out[:, k, d] = np.interp(new_idx, old_idx, xy_filled[:, k, d])\n",
    "        # mask: mark visible if majority of nearby frames were visible\n",
    "        vis = mask[:, k].astype(np.float32)\n",
    "        out_mask[:, k] = np.interp(new_idx, old_idx, vis) > 0.5\n",
    "    return out, out_mask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
